{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T20:17:12.151978Z",
     "iopub.status.busy": "2023-04-24T20:17:12.151566Z",
     "iopub.status.idle": "2023-04-24T20:17:12.173342Z",
     "shell.execute_reply": "2023-04-24T20:17:12.172317Z",
     "shell.execute_reply.started": "2023-04-24T20:17:12.151945Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=32\n",
    "Z_dim=100\n",
    "fixed_noise=torch.randn(32,Z_dim,1,1).to(device)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels, hidden_features=[64,128,256]):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.features=hidden_features\n",
    "        self.layers=nn.ModuleList()\n",
    "        \n",
    "        #adding first conv layer in the module list it does not have a Batch normalization\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.features[0], kernel_size=4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        #adding hidden layers\n",
    "        for i in range(len(self.features)-1):\n",
    "            self.layers.append(conv_block(self.features[i],self.features[i+1], 4, 2, 1))\n",
    "            \n",
    "        #adding the final layer\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.features[-1], 1, kernel_size=4, stride=2, padding=0),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in self.layers:\n",
    "#             print(x.shape)\n",
    "            x=i(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# modelD=Discriminator(1)\n",
    "# print(modelD)\n",
    "        \n",
    "    \n",
    "class transpose_conv_block(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(transpose_conv_block, self).__init__()\n",
    "        \n",
    "        self.conv=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "            \n",
    "\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,Z_dim, out_channels, hidden_features=[512,256,128]):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.features=hidden_features\n",
    "        self.layers=nn.ModuleList()\n",
    "        \n",
    "        #adding first conv layer in the module list it does not have a Batch normalization\n",
    "        self.layers.append(\n",
    "                nn.ConvTranspose2d(Z_dim, self.features[0], kernel_size=4, stride=1, padding=0)\n",
    "            )\n",
    "        \n",
    "        #adding hidden layers\n",
    "        for i in range(len(self.features)-1):\n",
    "            self.layers.append(transpose_conv_block(self.features[i],self.features[i+1], 4, 2, 1))\n",
    "            \n",
    "        #adding the final layer\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                transpose_conv_block(self.features[-1], out_channels, kernel_size=4, stride=2, padding=1),\n",
    "#                 nn.Tanh()\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in self.layers:\n",
    "#             print(x.shape)\n",
    "            x=i(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "# modelD=Generator(100,1)\n",
    "# print(modelD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T20:17:13.622865Z",
     "iopub.status.busy": "2023-04-24T20:17:13.622450Z",
     "iopub.status.idle": "2023-04-24T20:17:14.634926Z",
     "shell.execute_reply": "2023-04-24T20:17:14.633777Z",
     "shell.execute_reply.started": "2023-04-24T20:17:13.622827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#     transforms.Resize(64),\n",
    "     transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Load the test set\n",
    "# testset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "#                                        download=True, transform=transform)\n",
    "# test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T20:17:21.779395Z",
     "iopub.status.busy": "2023-04-24T20:17:21.778766Z",
     "iopub.status.idle": "2023-04-24T20:17:21.839210Z",
     "shell.execute_reply": "2023-04-24T20:17:21.838190Z",
     "shell.execute_reply.started": "2023-04-24T20:17:21.779355Z"
    }
   },
   "outputs": [],
   "source": [
    "modelG=Generator(100,3).to(device)\n",
    "modelD=Discriminator(3).to(device)\n",
    "optimizerG=torch.optim.Adam(modelG.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "optimizerD=torch.optim.Adam(modelD.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "lossFunction=nn.BCELoss()\n",
    "\n",
    "def GenerateImages(fixed_noise,ep):\n",
    "    fakes=modelG(fixed_noise)\n",
    "    images_np = np.transpose(fakes.cpu().detach().numpy(), (0, 2, 3, 1))\n",
    "    fig, axs = plt.subplots(4, 8, figsize=(20, 10))\n",
    "    axs = axs.ravel()\n",
    "    for i in range(images_np.shape[0]):\n",
    "        axs[i].imshow(images_np[i])\n",
    "        axs[i].axis('off')\n",
    "    # plt.show()\n",
    "    plt.savefig(f'{ep}_GI.png')\n",
    "    plt.close('all')\n",
    "    \n",
    "\n",
    "def train(epoch=25):\n",
    "    for ep in range(epoch):\n",
    "        for i, (img,_) in enumerate(train_loader):\n",
    "            #input for the discriminator\n",
    "            img=img.to(device)\n",
    "            # input for the generator\n",
    "            noise=torch.randn(batch_size, Z_dim, 1, 1).to(device)\n",
    "            \n",
    "            #Generating the image from the noise\n",
    "            imgG=modelG(noise)\n",
    "            \n",
    "            #calculating the loss for the image in the distribution\n",
    "            imgD=modelD(img).reshape(-1)\n",
    "            lossD=lossFunction(imgD,torch.ones_like(imgD))\n",
    "            \n",
    "            #calculating the loss for the generated image\n",
    "            fake=modelD(imgG).reshape(-1)\n",
    "            lossFake=lossFunction(fake,torch.zeros_like(fake))\n",
    "            \n",
    "            #optimizing the discriminator\n",
    "            modelD.zero_grad()\n",
    "            total_loss=(lossFake+lossD)/2\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "            \n",
    "            #optimizing the generator\n",
    "            output=modelD(imgG).reshape(-1)\n",
    "            lossG=lossFunction(output,torch.ones_like(output))\n",
    "            modelG.zero_grad()\n",
    "            lossG.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "        torch.save(modelG.state_dict(), f'Generator')\n",
    "        torch.save(modelD.state_dict(), f'Discriminator')\n",
    "#         torch.save(modelG.state_dict(), f'{ep}_Generator')\n",
    "#         torch.save(modelD.state_dict(), f'{ep}_Discriminator')\n",
    "        GenerateImages(fixed_noise,ep+1)\n",
    "        print(f'{ep+1} epoch Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T20:17:23.717218Z",
     "iopub.status.busy": "2023-04-24T20:17:23.716112Z",
     "iopub.status.idle": "2023-04-24T20:34:56.056950Z",
     "shell.execute_reply": "2023-04-24T20:34:56.055775Z",
     "shell.execute_reply.started": "2023-04-24T20:17:23.717160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch Finished\n",
      "2 epoch Finished\n",
      "3 epoch Finished\n",
      "4 epoch Finished\n",
      "5 epoch Finished\n",
      "6 epoch Finished\n",
      "7 epoch Finished\n",
      "8 epoch Finished\n",
      "9 epoch Finished\n",
      "10 epoch Finished\n",
      "11 epoch Finished\n",
      "12 epoch Finished\n",
      "13 epoch Finished\n",
      "14 epoch Finished\n",
      "15 epoch Finished\n",
      "16 epoch Finished\n",
      "17 epoch Finished\n",
      "18 epoch Finished\n",
      "19 epoch Finished\n",
      "20 epoch Finished\n",
      "21 epoch Finished\n",
      "22 epoch Finished\n",
      "23 epoch Finished\n",
      "24 epoch Finished\n",
      "25 epoch Finished\n"
     ]
    }
   ],
   "source": [
    "#generated images before training\n",
    "GenerateImages(fixed_noise,0)\n",
    "train(epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T20:36:09.977281Z",
     "iopub.status.busy": "2023-04-24T20:36:09.976675Z",
     "iopub.status.idle": "2023-04-24T20:36:12.408472Z",
     "shell.execute_reply": "2023-04-24T20:36:12.407078Z",
     "shell.execute_reply.started": "2023-04-24T20:36:09.977234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click below link to download the Generated images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='GI.zip' target='_blank'>GI.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/GI.zip"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To download all the generated images as a zip file execut the following command\n",
    "# only if working in kaggle\n",
    "\n",
    "from IPython.display import FileLink \n",
    "\n",
    "!cd \"/kaggle/working/\"\n",
    "!zip -q GI.zip `find \"/kaggle/working/\" -type f -name '*_GI.png'`\n",
    "print(\"Click below link to download the Generated images\")\n",
    "FileLink(r'GI.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
